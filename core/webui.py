import gradio as gr
import logging
import time
from typing import Dict, List, Any, Tuple
from utils.logger import get_logger
from core.model_controller import ModelController

logger = get_logger(__name__)

class WebUI:
    """WebUIæœåŠ¡ - æä¾›Webç®¡ç†ç•Œé¢"""

    def __init__(self, model_controller: ModelController):
        self.model_controller = model_controller
        self.model_manager_instance = model_controller
        self.UI_REFRESH_INTERVAL = 2
        self.LOG_REFRESH_INTERVAL = 1

    def get_gpu_status(self) -> List[List[str]]:
        """è·å–GPUçŠ¶æ€"""
        try:
            gpu_status = []
            for device_name, device_plugin in self.model_controller.device_plugins.items():
                if device_plugin.is_online():
                    total_mb, available_mb, used_mb = device_plugin.get_memory_info()
                    gpu_status.append([
                        device_name,
                        f"{used_mb}/{total_mb} MB",
                        f"{available_mb} MB å¯ç”¨"
                    ])

            if not gpu_status:
                return [["N/A", "æœªæ£€æµ‹åˆ°è®¾å¤‡", "N/A"]]

            return gpu_status
        except Exception as e:
            logger.error(f"WebUIè·å–è®¾å¤‡ä¿¡æ¯å¤±è´¥: {e}")
            return []

    def refresh_ui_data(self):
        """åˆ·æ–°UIæ•°æ®"""
        while True:
            try:
                gpu_status = self.get_gpu_status()
                all_model_status = self.model_controller.get_all_models_status()

                active_models = [
                    name for name, data in all_model_status.items()
                    if data['status'] not in ['stopped', 'failed']
                ]

                log_dropdown_update = gr.update(
                    choices=active_models if active_models else ["æ— æ´»åŠ¨æ¨¡å‹"]
                )

                status_updates = []
                requests_updates = []

                for name, data in sorted(all_model_status.items()):
                    status_updates.append(data['status'].capitalize())
                    requests_updates.append(data['pending_requests'])

                yield (
                    gpu_status,
                    log_dropdown_update,
                    *status_updates,
                    *requests_updates
                )

            except Exception as e:
                logger.error(f"UIåˆ·æ–°å¾ªç¯å‡ºé”™: {e}")
                yield (
                    self.get_gpu_status() or [],
                    gr.update(choices=["åˆ·æ–°å‡ºé”™"]),
                    *([""] * 100)
                )

            time.sleep(self.UI_REFRESH_INTERVAL)

    def get_current_log_model_and_output(self, log_model_select_value: str, active_models: List[str]) -> Tuple[str, str]:
        """è·å–å½“å‰åº”è¯¥æ˜¾ç¤ºçš„æ—¥å¿—æ¨¡å‹å’Œå¯¹åº”çš„æ—¥å¿—è¾“å‡º"""
        if not active_models:
            return "æ— æ´»åŠ¨æ¨¡å‹", "è¯·ä»ä¸Šæ–¹é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ä»¥æŸ¥çœ‹å…¶æ—¥å¿—ã€‚"

        # å¦‚æœå½“å‰é€‰æ‹©çš„æ¨¡å‹ä¸åœ¨æ´»åŠ¨æ¨¡å‹åˆ—è¡¨ä¸­ï¼Œåˆ™é€‰æ‹©ç¬¬ä¸€ä¸ªæ´»åŠ¨æ¨¡å‹
        if log_model_select_value not in active_models and log_model_select_value != "æ— æ´»åŠ¨æ¨¡å‹":
            selected_model = active_models[0] if active_models else "æ— æ´»åŠ¨æ¨¡å‹"
        else:
            selected_model = log_model_select_value

        # è·å–é€‰ä¸­æ¨¡å‹çš„æ—¥å¿—
        if selected_model == "æ— æ´»åŠ¨æ¨¡å‹":
            log_output = "è¯·ä»ä¸Šæ–¹é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ä»¥æŸ¥çœ‹å…¶æ—¥å¿—ã€‚"
        else:
            try:
                log_lines = self.model_controller.get_model_log(selected_model)
                log_output = "\n".join(log_lines)
            except Exception as e:
                logger.error(f"è·å–æ—¥å¿—æ—¶å‡ºé”™ {selected_model}: {e}")
                log_output = f"è·å– {selected_model} æ—¥å¿—æ—¶å‡ºé”™ã€‚"

        return selected_model, log_output

    def stream_log_output(self, model_name: str):
        """æµå¼è¾“å‡ºæ—¥å¿—"""
        if not model_name or model_name == "æ— æ´»åŠ¨æ¨¡å‹":
            yield "è¯·ä»ä¸Šæ–¹é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ä»¥æŸ¥çœ‹å…¶æ—¥å¿—ã€‚"
            return

        while True:
            try:
                log_lines = self.model_controller.get_model_log(model_name)
                yield "\n".join(log_lines)
            except Exception as e:
                logger.error(f"åˆ·æ–°æ—¥å¿—æ—¶å‡ºé”™ {model_name}: {e}")
                yield f"è·å– {model_name} æ—¥å¿—æ—¶å‡ºé”™ã€‚"

            time.sleep(self.LOG_REFRESH_INTERVAL)

    def create_model_control_row(self, primary_name: str, status_data: dict, index: int):
        """åˆ›å»ºæ¨¡å‹æ§åˆ¶è¡Œ"""
        with gr.Row(variant="panel"):
            with gr.Column(scale=3):
                gr.Markdown(f"**{primary_name}**")

                mode_display = status_data.get('mode', 'Chat')
                mode_emoji = {
                    "Chat": "ğŸ’¬",
                    "Base": "ğŸ“",
                    "Embedding": "ğŸ”",
                    "Reranker": "ğŸ”„"
                }.get(mode_display, "ğŸ¤–")

                gr.Markdown(f"<small>{mode_emoji} æ¨¡å¼: {mode_display}</small>")

                if status_data['aliases'][1:]:
                    aliases_str = ", ".join(status_data['aliases'][1:])
                    gr.Markdown(f"<small>åˆ«å: {aliases_str}</small>")

            with gr.Column(scale=5, min_width=400):
                with gr.Row():
                    status_box = gr.Textbox(
                        value=status_data['status'].capitalize(),
                        label="çŠ¶æ€",
                        interactive=False,
                        scale=1,
                        elem_id=f"status_box_{index}",
                        min_width=200
                    )
                    requests_box = gr.Textbox(
                        value=status_data['pending_requests'],
                        label="å¾…å¤„ç†è¯·æ±‚",
                        interactive=False,
                        scale=1,
                        elem_id=f"requests_box_{index}",
                        min_width=200
                    )

            with gr.Column(scale=3, min_width=240):
                with gr.Row():
                    start_btn = gr.Button("å¯åŠ¨", variant="primary", size="sm")
                    stop_btn = gr.Button("åœæ­¢", variant="stop", size="sm")

        start_btn.click(
            fn=lambda p_name=primary_name: self.model_controller.start_model(alias=p_name),
            inputs=[],
            outputs=[]
        ).then(lambda: gr.Info(f"å·²å‘é€å¯åŠ¨ '{primary_name}' çš„æŒ‡ä»¤..."), None, None)

        stop_btn.click(
            fn=lambda p_name=primary_name: self.model_controller.stop_model(alias=p_name),
            inputs=None,
            outputs=None
        ).then(lambda: gr.Info(f"å·²å‘é€åœæ­¢ '{primary_name}' çš„æŒ‡ä»¤..."), None, None)

        return status_box, requests_box

    def run(self, host: str, port: int):
        """è¿è¡ŒWebUIæœåŠ¡"""
        custom_css = """
            .console-output textarea {
                background-color: #000000 !important;
                color: #ffffff !important;
                font-family: 'Consolas', 'Monaco', 'Courier New', monospace !important;
                font-size: 14px !important;
                line-height: 1.4 !important;
                border: 1px solid #333333 !important;
                border-radius: 4px !important;
                resize: none !important;
                height: 580px !important;
                max-height: 580px !important;
                overflow-y: auto !important;
                width: 100% !important;
                min-width: 100% !important;
            }

            .console-output .gr-textbox {
                height: 600px !important;
                max-height: 600px !important;
                overflow-y: auto !important;
                flex-grow: 0 !important;
                flex-shrink: 0 !important;
                width: 100% !important;
                min-width: 100% !important;
            }

            .console-output .gr-textbox::-webkit-scrollbar {
                width: 12px !important;
            }

            .console-output .gr-textbox::-webkit-scrollbar-thumb {
                background: #888 !important;
                border-radius: 6px !important;
            }

            .console-output .gr-textbox::-webkit-scrollbar-thumb:hover {
                background: #555 !important;
            }

            .console-output {
                height: 600px !important;
                max-height: 600px !important;
                overflow-y: hidden !important;
                flex-grow: 0 !important;
                flex-shrink: 0 !important;
                width: 100% !important;
                min-width: 100% !important;
            }

            .console-output-wrapper {
                height: 600px !important;
                max-height: 600px !important;
                overflow: hidden !important;
                flex-grow: 0 !important;
                flex-shrink: 0 !important;
                width: 100% !important;
                min-width: 100% !important;
            }

            .model-scroll-container {
                height: 600px !important;
                overflow-y: auto !important;
                padding-right: 10px !important;
                border: 1px solid #e0e0e0 !important;
                border-radius: 8px !important;
                background-color: #f8f9fa !important;
            }

            .model-scroll-container::-webkit-scrollbar {
                width: 12px !important;
            }

            .model-scroll-container::-webkit-scrollbar-thumb {
                background: #888 !important;
                border-radius: 6px !important;
            }

            .model-scroll-container::-webkit-scrollbar-thumb:hover {
                background: #555 !important;
            }

            #main-title {
                text-align: center;
                margin-bottom: 20px !important;
            }

            .gpu-monitor {
                margin-bottom: 20px;
                padding: 15px;
            }

            .model-panel {
                padding: 15px;
                height: 100%;
                display: flex;
                flex-direction: column;
            }

            .log-panel {
                padding: 15px;
                height: 100%;
                display: flex;
                flex-direction: column;
            }

            .panel-content {
                flex: 1;
                display: flex;
                flex-direction: column;
            }

            .log-panel .gr-box {
                height: auto !important;
            }

            .log-panel .gradio-row {
                flex-grow: 0 !important;
                flex-shrink: 0 !important;
                width: 100% !important;
            }

            .log-panel .panel-content > :last-child {
                flex-grow: 0 !important;
                flex-shrink: 0 !important;
                width: 100% !important;
            }

            .log-panel {
                max-height: 800px !important;
                overflow: hidden !important;
                width: 100% !important;
            }

            .console-output-wrapper .gradio-row {
                width: 100% !important;
                min-width: 100% !important;
            }

            .console-output-wrapper {
                width: 100% !important;
                min-width: 100% !important;
            }

            .gradio-container {
                background-color: inherit !important;
            }
        """

        with gr.Blocks(title="LLM-Manager", theme=gr.themes.Soft(), css=custom_css) as ui:
            gr.Markdown("# ğŸ§  LLM-Manager æ§åˆ¶å°", elem_id="main-title")

            status_boxes = []
            requests_boxes = []

            with gr.Row():
                with gr.Column(elem_classes="gpu-monitor"):
                    gr.Markdown("## ğŸ–¥ï¸ è®¾å¤‡å®æ—¶ç›‘æ§")
                    gpu_table = gr.DataFrame(
                        headers=["è®¾å¤‡åç§°", "å†…å­˜ä½¿ç”¨", "å¯ç”¨å†…å­˜"],
                        datatype=["str", "str", "str"],
                        interactive=False,
                        row_count=(1, "fixed")
                    )

            with gr.Row():
                with gr.Column(scale=1, elem_classes="model-panel"):
                    gr.Markdown("## ğŸš€ æ¨¡å‹æ§åˆ¶é¢æ¿")
                    gr.Markdown("<small>é¢æ¿ä¸­çš„æ¨¡å‹çŠ¶æ€å’Œè¯·æ±‚æ•°ä¼šå®æ—¶æ›´æ–°ã€‚</small>")

                    with gr.Column(elem_classes="panel-content"):
                        with gr.Column(elem_classes="model-scroll-container"):
                            all_model_status = self.model_controller.get_all_models_status()
                            if not all_model_status:
                                gr.Markdown("âŒ **é”™è¯¯**: é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹é…ç½®ã€‚")
                            else:
                                sorted_models = sorted(all_model_status.items())
                                for i, (name, data) in enumerate(sorted_models):
                                    status_box, requests_box = self.create_model_control_row(name, data, i)
                                    status_boxes.append(status_box)
                                    requests_boxes.append(requests_box)

                with gr.Column(scale=3, elem_classes="log-panel"):
                    gr.Markdown("## ğŸ“œ æ¨¡å‹å®æ—¶æ—¥å¿—")
                    gr.Markdown("<small>âš ï¸ æ³¨æ„ï¼šå½“å¯åŠ¨æˆ–åœæ­¢æ¨¡å‹åï¼Œè¯·æ‰‹åŠ¨åˆ·æ–°é¡µé¢ä»¥æ›´æ–°æ—¥å¿—æ˜¾ç¤ºé€‰é¡¹ã€‚</small>")

                    with gr.Column(elem_classes="panel-content"):
                        with gr.Row():
                            log_model_select = gr.Dropdown(
                                label="é€‰æ‹©ä¸€ä¸ªæ´»åŠ¨ä¸­çš„æ¨¡å‹æŸ¥çœ‹æ—¥å¿—",
                                choices=["æ— æ´»åŠ¨æ¨¡å‹"],
                                container=False
                            )

                        with gr.Row(elem_classes="console-output-wrapper"):
                            log_output = gr.Textbox(
                                label="æ§åˆ¶å°è¾“å‡º",
                                lines=30,
                                interactive=False,
                                max_lines=2000,
                                autoscroll=False,
                                elem_classes="console-output"
                            )

            ui.load(
                fn=self.refresh_ui_data,
                inputs=None,
                outputs=[gpu_table, log_model_select] + status_boxes + requests_boxes
            )

            log_model_select.change(
                fn=self.stream_log_output,
                inputs=log_model_select,
                outputs=log_output,
                show_progress="hidden"
            )

        logger.info(f"WebUI ç®¡ç†ç•Œé¢å°†åœ¨ http://{host}:{port} ä¸Šå¯åŠ¨")

        # è®¾ç½®ç¯å¢ƒå˜é‡
        import os
        os.environ["GRADIO_SERVER_NAME"] = host
        os.environ["GRADIO_SERVER_PORT"] = str(port)
        os.system("chcp 65001 >nul")

        ui.queue().launch(server_name=host, server_port=port, share=False)

def run_web_ui(model_controller: ModelController, host: str, port: int):
    """è¿è¡ŒWebUIçš„ä¾¿æ·å‡½æ•°"""
    webui = WebUI(model_controller)
    webui.run(host, port)